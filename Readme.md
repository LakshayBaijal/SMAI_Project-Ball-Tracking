## SMAI Project

### Youtube Video

```bash
https://www.youtube.com/watch?v=s2lVYqKBQPE
```

### Ball Tracking Results.

https://github.com/user-attachments/assets/f7501964-5db0-43c4-8fa5-f4a58084c32e

https://github.com/user-attachments/assets/a6eb28c6-14dd-4069-aa4a-199b15a84319



## ğŸ“ Dataset and Preprocessing

- **Dataset**: TTNet dataset, which provides JSON-based annotations for table tennis ball positions in each frame.
- **Focus**: Only the **ball** is detected (no table or player detection).


## ğŸ“ Directory Structure:
    ```
    yolo_dataset/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â””â”€â”€ labels/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â”œâ”€â”€ ball_analysis.py
    â”œâ”€â”€ classes.txt
    â”œâ”€â”€ track_ball.py
    â”œâ”€â”€ ttnet_ball.yaml
    â”œâ”€â”€ yolov8n.pt
    â”œâ”€â”€ Dataset_Generation/
        â”œâ”€â”€ download_dataset.py
        â”œâ”€â”€ extract_all_images.py
        â””â”€â”€ extract_selected_images.py
    â””â”€â”€ convert_ball_to_yolo.py
    
    ```

---

## âš™ï¸ Model Training

- **Model Used**: `yolov8n.pt` (Nano version for faster training).
- **Training Command**:
  ```bash
  yolo train model=yolov8n.pt data=ttnet_ball.yaml epochs=20 imgsz=640 batch=16 project=TTBallProject name=ball_yolo_model
  ```

## ğŸ” Inference
- **Command**:
  ```bash
  yolo predict model=TTBallProject/ball_yolo_model/weights/best.pt source=videos/TT1.mp4 conf=0.25 save=True
  ```

- This generates an annotated output video with bounding boxes around detected balls.

## ğŸ“ˆ Post-Processing: Speed & Direction
- A script (post_process_speed_angle.py) was implemented to:

- Read YOLO predictions from .txt files.

- Calculate speed using Euclidean distance between detected centers in consecutive frames.

- Compute direction using arctangent (atan2) function.

- Annotate video with speed (px/frame) and angle (degrees).

- Distance: d = sqrt((x2 - x1)^2 + (y2 - y1)^2)
- Speed: speed = d / time_between_frames
- Direction - angle = atan2(y2 - y1, x2 - x1) Ã— (180 / Ï€)
- Final Output: Annotated video with bounding boxes, speed, and direction arrow.

## ğŸ“Œ Notes

- Trained entirely locally due to GPU session limits in Kaggle.

- Focused only on ball tracking.

- Could be extended to detect bounce events, estimate speed in m/s, or predict ball trajectory.

## Metrics

![image](https://github.com/user-attachments/assets/686eb691-fdfc-4b1f-8d94-327b5de37395)
![image](https://github.com/user-attachments/assets/3c3f3fe5-ac82-486b-aac4-a90eeadf651e)

- Precision : 89.09%
- Recall : 62.69%
- F1-score : 73.5%
- mAP50	: 77.98%

## ğŸ“ Links
- Dataset Sample (Converted to YOLO format)
  ```bash
  https://www.kaggle.com/datasets/svmohitkumar/smai-project-dataset
  ```
- Video on Implementation of Ball Tracking (Voice Reveal Here)
  ```bash
  https://www.youtube.com/watch?v=s2lVYqKBQPE
  ```
- Reports about this Project
  ```bash
  https://github.com/LakshayBaijal/SMAI_Project/tree/main/Submissions
  ``` 
